// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

#include <cstdint>

template <int64_t atom_h, int64_t atom_w>
void conv_dw_f3s2_h3w4_kernel_riscv_fp16(
    const __fp16* src,
    const __fp16* flt,
    const __fp16* bias,
    __fp16* dst,

    int64_t src_pad_w,
    int64_t dst_h,
    int64_t dst_w)
{
    asm volatile(
        ".equ           ATOM_H, %c[ATOM_H]      \n\t"
        ".equ           ATOM_W, %c[ATOM_W]      \n\t"

        "addi           t0,     zero,   8       \n\t"
        "vsetvli        t1,     t0,     e16     \n\t"

        "mv             t0,     %[SRC]          \n\t"
        "mv             t1,     %[FLT]          \n\t"
        "mv             t2,     %[BIAS]         \n\t"
        "mv             t3,     %[DST]          \n\t"
        "mv             t4,     %[H_STRIDE]     \n\t"
        "mv             t5,     %[DST_H]        \n\t"
        "mv             t6,     %[DST_W]        \n\t"

        "addi           s2,     zero,   3       \n\t"
        "addi           s3,     zero,   4       \n\t"

        // load filter: v12-v20
        //      bias  : v21
        "vle.v          v12,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v13,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v14,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v15,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v16,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v17,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v18,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v19,    (t1)            \n\t"
        "addi           t1,     t1,     16      \n\t"
        "vle.v          v20,    (t1)            \n\t"

        "vle.v          v21,    (t2)            \n\t"

        "addi           t1,     zero,   16      \n\t"
        "mul            t2,     t6,     t1      \n\t" // dst_h_stride

        "0:                                     \n\t"
        "mv             s4,     t0              \n\t"
        "mv             s8,     t3              \n\t"
        "blt            t5,     s2,     4f      \n\t"
        "mv             s6,     t5              \n\t"
        "blt            t6,     s3,     2f      \n\t"
        "mv             s7,     t6              \n\t"

        "1:                                     \n\t"
        "vmv.v.v        v0,     v21             \n\t"
        "vmv.v.v        v1,     v21             \n\t"
        "vmv.v.v        v2,     v21             \n\t"
        "vmv.v.v        v3,     v21             \n\t"
        "vmv.v.v        v4,     v21             \n\t"
        "vmv.v.v        v5,     v21             \n\t"
        "vmv.v.v        v6,     v21             \n\t"
        "vmv.v.v        v7,     v21             \n\t"
        "vmv.v.v        v8,     v21             \n\t"
        "vmv.v.v        v9,     v21             \n\t"
        "vmv.v.v        v10,    v21             \n\t"
        "vmv.v.v        v11,    v21             \n\t"
        // load src : v22-v30 (line 0)
        "mv             s10,    s4              \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v12,    v22     \n\t"
        "vfmacc.vv      v1,     v12,    v24     \n\t"
        "vfmacc.vv      v2,     v12,    v26     \n\t"
        "vfmacc.vv      v3,     v12,    v28     \n\t"

        "vfmacc.vv      v0,     v13,    v23     \n\t"
        "vfmacc.vv      v1,     v13,    v25     \n\t"
        "vfmacc.vv      v2,     v13,    v27     \n\t"
        "vfmacc.vv      v3,     v13,    v29     \n\t"

        "vfmacc.vv      v0,     v14,    v24     \n\t"
        "vfmacc.vv      v1,     v14,    v26     \n\t"
        "vfmacc.vv      v2,     v14,    v28     \n\t"
        "vfmacc.vv      v3,     v14,    v30     \n\t"
        // load src : line 1
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v15,    v22     \n\t"
        "vfmacc.vv      v1,     v15,    v24     \n\t"
        "vfmacc.vv      v2,     v15,    v26     \n\t"
        "vfmacc.vv      v3,     v15,    v28     \n\t"

        "vfmacc.vv      v0,     v16,    v23     \n\t"
        "vfmacc.vv      v1,     v16,    v25     \n\t"
        "vfmacc.vv      v2,     v16,    v27     \n\t"
        "vfmacc.vv      v3,     v16,    v29     \n\t"

        "vfmacc.vv      v0,     v17,    v24     \n\t"
        "vfmacc.vv      v1,     v17,    v26     \n\t"
        "vfmacc.vv      v2,     v17,    v28     \n\t"
        "vfmacc.vv      v3,     v17,    v30     \n\t"
        // load src : line 2
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v18,    v22     \n\t"
        "vfmacc.vv      v1,     v18,    v24     \n\t"
        "vfmacc.vv      v2,     v18,    v26     \n\t"
        "vfmacc.vv      v3,     v18,    v28     \n\t"
        "vfmacc.vv      v4,     v12,    v22     \n\t"
        "vfmacc.vv      v5,     v12,    v24     \n\t"
        "vfmacc.vv      v6,     v12,    v26     \n\t"
        "vfmacc.vv      v7,     v12,    v28     \n\t"

        "vfmacc.vv      v0,     v19,    v23     \n\t"
        "vfmacc.vv      v1,     v19,    v25     \n\t"
        "vfmacc.vv      v2,     v19,    v27     \n\t"
        "vfmacc.vv      v3,     v19,    v29     \n\t"
        "vfmacc.vv      v4,     v13,    v23     \n\t"
        "vfmacc.vv      v5,     v13,    v25     \n\t"
        "vfmacc.vv      v6,     v13,    v27     \n\t"
        "vfmacc.vv      v7,     v13,    v29     \n\t"

        "vfmacc.vv      v0,     v20,    v24     \n\t"
        "vfmacc.vv      v1,     v20,    v26     \n\t"
        "vfmacc.vv      v2,     v20,    v28     \n\t"
        "vfmacc.vv      v3,     v20,    v30     \n\t"
        "vfmacc.vv      v4,     v14,    v24     \n\t"
        "vfmacc.vv      v5,     v14,    v26     \n\t"
        "vfmacc.vv      v6,     v14,    v28     \n\t"
        "vfmacc.vv      v7,     v14,    v30     \n\t"

        "mv             s11,    s8              \n\t"
        "vse.v          v0,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        "vse.v          v1,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v2,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v3,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        // load src : line 3
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v4,     v15,    v22     \n\t"
        "vfmacc.vv      v5,     v15,    v24     \n\t"
        "vfmacc.vv      v6,     v15,    v26     \n\t"
        "vfmacc.vv      v7,     v15,    v28     \n\t"

        "vfmacc.vv      v4,     v16,    v23     \n\t"
        "vfmacc.vv      v5,     v16,    v25     \n\t"
        "vfmacc.vv      v6,     v16,    v27     \n\t"
        "vfmacc.vv      v7,     v16,    v29     \n\t"

        "vfmacc.vv      v4,     v17,    v24     \n\t"
        "vfmacc.vv      v5,     v17,    v26     \n\t"
        "vfmacc.vv      v6,     v17,    v28     \n\t"
        "vfmacc.vv      v7,     v17,    v30     \n\t"
        // load src : line 4
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v4,     v18,    v22     \n\t"
        "vfmacc.vv      v5,     v18,    v24     \n\t"
        "vfmacc.vv      v6,     v18,    v26     \n\t"
        "vfmacc.vv      v7,     v18,    v28     \n\t"
        "vfmacc.vv      v8,     v12,    v22     \n\t"
        "vfmacc.vv      v9,     v12,    v24     \n\t"
        "vfmacc.vv      v10,    v12,    v26     \n\t"
        "vfmacc.vv      v11,    v12,    v28     \n\t"

        "vfmacc.vv      v4,     v19,    v23     \n\t"
        "vfmacc.vv      v5,     v19,    v25     \n\t"
        "vfmacc.vv      v6,     v19,    v27     \n\t"
        "vfmacc.vv      v7,     v19,    v29     \n\t"
        "vfmacc.vv      v8,     v13,    v23     \n\t"
        "vfmacc.vv      v9,     v13,    v25     \n\t"
        "vfmacc.vv      v10,    v13,    v27     \n\t"
        "vfmacc.vv      v11,    v13,    v29     \n\t"

        "vfmacc.vv      v4,     v20,    v24     \n\t"
        "vfmacc.vv      v5,     v20,    v26     \n\t"
        "vfmacc.vv      v6,     v20,    v28     \n\t"
        "vfmacc.vv      v7,     v20,    v30     \n\t"
        "vfmacc.vv      v8,     v14,    v24     \n\t"
        "vfmacc.vv      v9,     v14,    v26     \n\t"
        "vfmacc.vv      v10,    v14,    v28     \n\t"
        "vfmacc.vv      v11,    v14,    v30     \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v4,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        "vse.v          v5,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v6,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v7,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        // load src : line 5
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v8,     v15,    v22     \n\t"
        "vfmacc.vv      v9,     v15,    v24     \n\t"
        "vfmacc.vv      v10,    v15,    v26     \n\t"
        "vfmacc.vv      v11,    v15,    v28     \n\t"

        "vfmacc.vv      v8,     v16,    v23     \n\t"
        "vfmacc.vv      v9,     v16,    v25     \n\t"
        "vfmacc.vv      v10,    v16,    v27     \n\t"
        "vfmacc.vv      v11,    v16,    v29     \n\t"

        "vfmacc.vv      v8,     v17,    v24     \n\t"
        "vfmacc.vv      v9,     v17,    v26     \n\t"
        "vfmacc.vv      v10,    v17,    v28     \n\t"
        "vfmacc.vv      v11,    v17,    v30     \n\t"
        // load src : line 6
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v8,     v18,    v22     \n\t"
        "vfmacc.vv      v9,     v18,    v24     \n\t"
        "vfmacc.vv      v10,    v18,    v26     \n\t"
        "vfmacc.vv      v11,    v18,    v28     \n\t"

        "vfmacc.vv      v8,     v19,    v23     \n\t"
        "vfmacc.vv      v9,     v19,    v25     \n\t"
        "vfmacc.vv      v10,    v19,    v27     \n\t"
        "vfmacc.vv      v11,    v19,    v29     \n\t"

        "vfmacc.vv      v8,     v20,    v24     \n\t"
        "vfmacc.vv      v9,     v20,    v26     \n\t"
        "vfmacc.vv      v10,    v20,    v28     \n\t"
        "vfmacc.vv      v11,    v20,    v30     \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v8,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        "vse.v          v9,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v10,    (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v11,    (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        // loop control
        // loop_w
        "addi           s7,     s7,     -4      \n\t"
        "addi           s4,     s4,     128     \n\t"
        "addi           s8,     s8,     64      \n\t"
        "bge            s7,     s3,     1b      \n\t"
        "beq            s7,     zero,   3f      \n\t"

        "2:                                     \n\t"
        "vmv.v.v        v0,     v21             \n\t"
        "vmv.v.v        v4,     v21             \n\t"
        "vmv.v.v        v8,     v21             \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vmv.v.v        v1,     v21             \n\t"
        "vmv.v.v        v5,     v21             \n\t"
        "vmv.v.v        v9,     v21             \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vmv.v.v        v2,     v21             \n\t"
        "vmv.v.v        v6,     v21             \n\t"
        "vmv.v.v        v10,    v21             \n\t"
        ".endif                                 \n\t"
        // load src : line 0
        "mv             s10,    s4              \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v12,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v13,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v14,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 1
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v15,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v15,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v15,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v16,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v16,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v16,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v17,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v17,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v17,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 2
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v18,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v18,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v18,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v12,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v19,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v19,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v19,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v13,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v20,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v20,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v20,    v28     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v14,    v28     \n\t"
        ".endif                                 \n\t"

        "mv             s11,    s8              \n\t"
        "vse.v          v0,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vse.v          v1,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vse.v          v2,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        // load src : line 3
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v4,     v15,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v15,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v15,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v16,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v16,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v16,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v17,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v17,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v17,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 4
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v4,     v18,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v18,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v18,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v12,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v19,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v19,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v19,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v13,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v20,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v20,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v20,    v28     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v14,    v28     \n\t"
        ".endif                                 \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v4,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vse.v          v5,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vse.v          v6,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        // load src : line 5
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v8,     v15,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v15,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v15,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v16,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v16,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v16,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v17,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v17,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v17,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 6
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v8,     v18,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v18,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v18,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v19,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v19,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v19,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v20,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v20,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v20,    v28     \n\t"
        ".endif                                 \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v8,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vse.v          v9,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vse.v          v10,    (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"

        // loop control
        // loop_h
        "3:                                     \n\t"
        "addi           t5,     t5,     -3      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t0,     t0,     t4      \n\t"
        "add            t3,     t3,     t2      \n\t"
        "add            t3,     t3,     t2      \n\t"
        "add            t3,     t3,     t2      \n\t"
        "bge            t5,     s2,     0b      \n\t"
        "beq            t5,     zero,   7f      \n\t"

        "4:                                     \n\t"
        "mv             s4,     t0              \n\t"
        "mv             s8,     t3              \n\t"
        "blt            t6,     s3,     6f      \n\t"
        "mv             s7,     t6              \n\t"

        "5:                                     \n\t"
        "vmv.v.v        v0,     v21             \n\t"
        "vmv.v.v        v1,     v21             \n\t"
        "vmv.v.v        v2,     v21             \n\t"
        "vmv.v.v        v3,     v21             \n\t"
        ".if ATOM_H > 1                         \n\t"
        "vmv.v.v        v4,     v21             \n\t"
        "vmv.v.v        v5,     v21             \n\t"
        "vmv.v.v        v6,     v21             \n\t"
        "vmv.v.v        v7,     v21             \n\t"
        ".endif                                 \n\t"
        // load src : line 0
        "mv             s10,    s4              \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v12,    v22     \n\t"
        "vfmacc.vv      v1,     v12,    v24     \n\t"
        "vfmacc.vv      v2,     v12,    v26     \n\t"
        "vfmacc.vv      v3,     v12,    v28     \n\t"

        "vfmacc.vv      v0,     v13,    v23     \n\t"
        "vfmacc.vv      v1,     v13,    v25     \n\t"
        "vfmacc.vv      v2,     v13,    v27     \n\t"
        "vfmacc.vv      v3,     v13,    v29     \n\t"

        "vfmacc.vv      v0,     v14,    v24     \n\t"
        "vfmacc.vv      v1,     v14,    v26     \n\t"
        "vfmacc.vv      v2,     v14,    v28     \n\t"
        "vfmacc.vv      v3,     v14,    v30     \n\t"
        // load src : line 1
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v15,    v22     \n\t"
        "vfmacc.vv      v1,     v15,    v24     \n\t"
        "vfmacc.vv      v2,     v15,    v26     \n\t"
        "vfmacc.vv      v3,     v15,    v28     \n\t"

        "vfmacc.vv      v0,     v16,    v23     \n\t"
        "vfmacc.vv      v1,     v16,    v25     \n\t"
        "vfmacc.vv      v2,     v16,    v27     \n\t"
        "vfmacc.vv      v3,     v16,    v29     \n\t"

        "vfmacc.vv      v0,     v17,    v24     \n\t"
        "vfmacc.vv      v1,     v17,    v26     \n\t"
        "vfmacc.vv      v2,     v17,    v28     \n\t"
        "vfmacc.vv      v3,     v17,    v30     \n\t"
        // load src : line 2
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v0,     v18,    v22     \n\t"
        "vfmacc.vv      v1,     v18,    v24     \n\t"
        "vfmacc.vv      v2,     v18,    v26     \n\t"
        "vfmacc.vv      v3,     v18,    v28     \n\t"
        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v12,    v22     \n\t"
        "vfmacc.vv      v5,     v12,    v24     \n\t"
        "vfmacc.vv      v6,     v12,    v26     \n\t"
        "vfmacc.vv      v7,     v12,    v28     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v19,    v23     \n\t"
        "vfmacc.vv      v1,     v19,    v25     \n\t"
        "vfmacc.vv      v2,     v19,    v27     \n\t"
        "vfmacc.vv      v3,     v19,    v29     \n\t"
        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v13,    v23     \n\t"
        "vfmacc.vv      v5,     v13,    v25     \n\t"
        "vfmacc.vv      v6,     v13,    v27     \n\t"
        "vfmacc.vv      v7,     v13,    v29     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v20,    v24     \n\t"
        "vfmacc.vv      v1,     v20,    v26     \n\t"
        "vfmacc.vv      v2,     v20,    v28     \n\t"
        "vfmacc.vv      v3,     v20,    v30     \n\t"
        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v14,    v24     \n\t"
        "vfmacc.vv      v5,     v14,    v26     \n\t"
        "vfmacc.vv      v6,     v14,    v28     \n\t"
        "vfmacc.vv      v7,     v14,    v30     \n\t"
        ".endif                                 \n\t"

        "mv             s11,    s8              \n\t"
        "vse.v          v0,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        "vse.v          v1,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v2,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v3,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"

        ".if ATOM_H > 1                         \n\t"
        // load src : line 3
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v4,     v15,    v22     \n\t"
        "vfmacc.vv      v5,     v15,    v24     \n\t"
        "vfmacc.vv      v6,     v15,    v26     \n\t"
        "vfmacc.vv      v7,     v15,    v28     \n\t"

        "vfmacc.vv      v4,     v16,    v23     \n\t"
        "vfmacc.vv      v5,     v16,    v25     \n\t"
        "vfmacc.vv      v6,     v16,    v27     \n\t"
        "vfmacc.vv      v7,     v16,    v29     \n\t"

        "vfmacc.vv      v4,     v17,    v24     \n\t"
        "vfmacc.vv      v5,     v17,    v26     \n\t"
        "vfmacc.vv      v6,     v17,    v28     \n\t"
        "vfmacc.vv      v7,     v17,    v30     \n\t"
        // load src : line 4
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v29,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v30,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        // calculate
        "vfmacc.vv      v4,     v18,    v22     \n\t"
        "vfmacc.vv      v5,     v18,    v24     \n\t"
        "vfmacc.vv      v6,     v18,    v26     \n\t"
        "vfmacc.vv      v7,     v18,    v28     \n\t"

        "vfmacc.vv      v4,     v19,    v23     \n\t"
        "vfmacc.vv      v5,     v19,    v25     \n\t"
        "vfmacc.vv      v6,     v19,    v27     \n\t"
        "vfmacc.vv      v7,     v19,    v29     \n\t"

        "vfmacc.vv      v4,     v20,    v24     \n\t"
        "vfmacc.vv      v5,     v20,    v26     \n\t"
        "vfmacc.vv      v6,     v20,    v28     \n\t"
        "vfmacc.vv      v7,     v20,    v30     \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v4,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        "vse.v          v5,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v6,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        "vse.v          v7,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"

        "addi           s7,     s7,     -4      \n\t"
        "addi           s4,     s4,     128     \n\t"
        "addi           s8,     s8,     64      \n\t"
        "bge            s7,     s3,     5b      \n\t"
        "beq            s7,     zero,   7f      \n\t"

        "6:                                     \n\t"
        "vmv.v.v        v0,     v21             \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vmv.v.v        v1,     v21             \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vmv.v.v        v2,     v21             \n\t"
        ".endif                                 \n\t"
        ".if ATOM_H > 1                         \n\t"
        "vmv.v.v        v4,     v21             \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vmv.v.v        v5,     v21             \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vmv.v.v        v6,     v21             \n\t"
        ".endif                                 \n\t"
        ".endif                                 \n\t"
        // load src : line 0
        "mv             s10,    s4              \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v12,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v13,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v14,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 1
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v15,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v15,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v15,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v16,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v16,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v16,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v17,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v17,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v17,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 2
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v0,     v18,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v18,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v18,    v26     \n\t"
        ".endif                                 \n\t"

        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v12,    v26     \n\t"
        ".endif                                 \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v19,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v19,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v19,    v27     \n\t"
        ".endif                                 \n\t"

        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v13,    v27     \n\t"
        ".endif                                 \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v0,     v20,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v1,     v20,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v2,     v20,    v28     \n\t"
        ".endif                                 \n\t"

        ".if ATOM_H > 1                         \n\t"
        "vfmacc.vv      v4,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v14,    v28     \n\t"
        ".endif                                 \n\t"
        ".endif                                 \n\t"

        "mv             s11,    s8              \n\t"
        "vse.v          v0,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vse.v          v1,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vse.v          v2,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"

        ".if ATOM_H > 1                         \n\t"
        // load src : line 3
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v4,     v15,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v15,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v15,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v16,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v16,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v16,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v17,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v17,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v17,    v28     \n\t"
        ".endif                                 \n\t"
        // load src : line 4
        "add            s10,    s10,    t4      \n\t"
        "vle.v          v22,    (s10)           \n\t"
        "addi           s5,     s10,    16      \n\t"
        "vle.v          v23,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v24,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vle.v          v25,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v26,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vle.v          v27,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        "vle.v          v28,    (s5)            \n\t"
        "addi           s5,     s5,     16      \n\t"
        ".endif                                 \n\t"
        // calculate
        "vfmacc.vv      v4,     v18,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v18,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v18,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v12,    v22     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v12,    v24     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v12,    v26     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v19,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v19,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v19,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v13,    v23     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v13,    v25     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v13,    v27     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v4,     v20,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v5,     v20,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v6,     v20,    v28     \n\t"
        ".endif                                 \n\t"

        "vfmacc.vv      v8,     v14,    v24     \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vfmacc.vv      v9,     v14,    v26     \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vfmacc.vv      v10,    v14,    v28     \n\t"
        ".endif                                 \n\t"

        "add            s11,    s11,    t2      \n\t"
        "vse.v          v4,     (s11)           \n\t"
        "addi           s9,     s11,    16      \n\t"
        ".if ATOM_W > 1                         \n\t"
        "vse.v          v5,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".if ATOM_W > 2                         \n\t"
        "vse.v          v6,     (s9)            \n\t"
        "addi           s9,     s9,     16      \n\t"
        ".endif                                 \n\t"
        ".endif                                 \n\t"
        "7:                                     \n\t"
        "nop                                    \n\t"
        :
        : [ATOM_H] "i"(atom_h), [ATOM_W] "i"(atom_w), [SRC] "r"(src), [FLT] "r"(flt), [DST] "r"(dst), [BIAS] "r"(bias), [H_STRIDE] "r"(src_pad_w * 8 * 2), [DST_H] "r"(dst_h), [DST_W] "r"(dst_w)
        : "memory", "t0", "t1", "t2", "t3", "t4", "t5", "t6", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9", "s10", "s11", "v0", "v1", "v2", "v3", "v4", "v5", "v6", "v7", "v8", "v9", "v10", "v11", "v12", "v13", "v14", "v15", "v16", "v17", "v18", "v19", "v20", "v21", "v22", "v23", "v24", "v25", "v26", "v27", "v28", "v29", "v30", "v31");
}
